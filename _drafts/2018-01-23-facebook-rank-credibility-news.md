---
published: false
layout: post
tags:
  - fake news
  - ranking
  - facebook
  - users
---
Facebook has a fake news problem.

Almost every person, their friends, and their parents have been exposed to these. Fake news often comes in the form of clickbait-titled links, leading to [sensational articles which spread lies](https://www.engadget.com/2018/01/16/facebook-news-feed-tweak-could-make-fake-news-worse/).

# What is Facebook doing? 

According to [New York Times](https://www.nytimes.com/2018/01/19/technology/facebook-news-feed.html), it is asking users to evaluate the trustworthiness of news outlets. Data from this evaluation will be used to promote "trusted" sites over "untrusted" ones.

To me, the fake news problem has two sides:
- the evil author of the fake article or site
- the gullible reader/spreader of fake news

While the Facebook approach may tackle the evil author in some way, it is relying on data from the weaker actor of the problem: the gullible reader. 

# The cure is worse than the disease

This solution is bad on so many levels:
- fake news target gullible readers, so in principle one should not ask a deceivable person if a news outlet is trying to deceive him/her;
- the survey addresses [the whole site](http://www.telegraph.co.uk/technology/2018/01/24/facebook-defends-two-question-fake-news-survey/) and not the single news: what happens if a reputable site mistakenly bait on a fake news? I know this may sound unethical, but it happened in the past and will surely happen again;
- the readers can be targeted via facebook groups, which are not moderated via the same survey. Recent data have shown that russians have used groups to [spread fake news and bias people on religion and immigration](https://www.nytimes.com/2018/02/17/technology/indictment-russian-tech-facebook.html);
- what happens if a reputable site is targeted by a big group and purposely marked as "not trustworthy"? It may be showed less in people's timeline, losing users in the process

Hint: it won't work.
